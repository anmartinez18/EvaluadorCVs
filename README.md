# üîç Evaluador de CVs con IA Generativa üß†

Este sistema implementa un pipeline basado en modelos llm para la evaluaci√≥n de candidatos autom√°ticamente seg√∫n los requisitos de una oferta de empleo. La evaluaci√≥n se realiza en dos fases:

1. **Evaluaci√≥n inicial autom√°tica**: Se introduce el cv y la oferta de empleo, se aceptan archivos en formato pdf o txt, o simplemente texto libre. Si se carga un archivo y se incluye texto libre a la vez, el fichero adjuntado tendr√° prioridad. A continuaci√≥n, el sistema clasifica autom√°ticamente que requisitos se cumplen y cuales no. Como resultado se obtiene una puntuaci√≥n global ("score") y se indica si el candidato ha sido descartado o continua en el proceso gracias al valor de ("discarded").

2. **Evaluaci√≥n interactiva**: Si el candidato no ha sido descartado y existen requisitos no mencionados en el CV ("not_found_requirements"), que no sean obligatorios, el sistema realizar√° una breve entrevista al candidato y actualizar√° el resultado final en base a las respuestas proporcionadas. En caso contrario se finalizar√° la evaluaci√≥n.

El evaluador cuenta con una interfaz web interactiva para mejorar la experiencia del usuario. Est√° implementada con Gradio.

## Funcionalidades principales
- Extracci√≥n autom√°tica de requisitos.
- B√∫squeda y an√°lisis de evidencias en el CV para contrastar el cumplimiento de los requisitos.
- Puntuaci√≥n basada en el cumplimiento de requisitos. Si un requisito no se cumple se descarta al candidato autom√°ticamente.
- Conversaci√≥n interactiva con el candidato para completar el proceso.
- Sistema modular, permite cambiar el provedor del LLM de manera sencilla.

## Configurar LLM ‚úÖ

Para el desarrollo del sistema se ha utilizado un LLM de Mistral, concretamente el modelo llamado "mistral-large-latest".

En el carpeta 'src' existen los dos archivos necesarios para la configuraci√≥n del llm: 

- **"src/models.py"**: Aqu√≠ se a√±ade o se modifica el modelo LLM que se utilizar√°.

- **"src/.env"**: En este fichero se debe incluir la api_key necesaria para instanciar el modelo.


## Ejemplo de uso

 ```shell

# 1. Situarse en la siguiente ruta.
cd EvaluadorCVs

# 2. Instalar poetry (si no est√° ya instalado).
pip install poetry

# 3. Configurar que el entorno de ejecuci√≥n se cree dentro del proyecto (.venv).
poetry config virtualenvs.in-project true

# 4. Instalaci√≥n de dependencias y creaci√≥n del entorno.
poetry install

# 5. Activar entorno.
.\.venv\Scripts\activate

# 6. A√±adir nuevas dependencias (si es necesario para otros LLMs).
poetry add "dependencia"
poetry lock # Actualizar lock al a√±adir nuevas dependencias

# 7. Lanzar la aplicaci√≥n web con Gradio dentro del entorno creado.
python app.py

```

## Aclaraciones
- La applicaci√≥n web servir√° por defecto en la URL local: http://127.0.0.1:7862
- El puerto se puede modificar desde el fichero app.py editando la opci√≥n 'server_port=XXXX' en la √∫ltima linea de c√≥digo.
- Para crear un enlace totalmente p√∫blico sustituir la opci√≥n 'share=False' por 'share=True'.
